{
  
    
        "post0": {
            "title": "Designing Transparent Neural Networks",
            "content": "Most systems we interact with are part of some pipeline that integrates Machine Learning (ML). Sometimes we interact with an ML model directly, like Spotify&#39;s recommender system for songs. Other times, this interaction is more detatched; we post a comment on Twitter or Facebook, and this comment is used to train some language model at the respective company. As ML models become more and more prevalent, interpreting and explaining the decisions these models make become increasingly important. . Neural networks are a popular class of machine learning algorithms, which are notorious for being difficult to interpret. They are often referred to as &quot;black boxes&quot; or &quot;opaque&quot;. This blog post will explore a particular type of neural architecture that is inherrantly transparent. However, prior to jumping into that, it&#39;s important to understand the fundamental transparent algorithms, starting from the simplest linear models. The following section will provide a background on the math and fundamentals of linear and additive models, as well as how they relate to the inner mechanisms of neural networks1. . . Note: If you are familiar with GLMs, GAMs, and NNs, feel free to skip this introductory section. . . Introducing Linear and Additive Models . Linear models are one of the simplest approaches to supervised learning. The general goal of supervised learning is to discover some function $f$ that minimizes an error-term $ epsilon$ given a set of input features $X$ and a corresponding target $y$ such that $y = f(X) + epsilon$. Additionally, the output of a supervised model is often written as $ hat{y} = f(X)$ because $f(X)$ is our best approximation of $y$. . Different algorithms are sufficient for learning different functions. Simple linear models can only learn to make predictions according to functions of the form: . $$y = X^T beta + epsilon = beta_0 + beta_1 X_1 + beta_2 X_2 + cdots + beta_n X_n + epsilon$$ . Where $ beta_i$ represents learned coefficients with respect to $X_i$, and $T$ is the transpose operation, which in this case is basically identical to computing the dot product of two n-dimensional vectors. . Linear Regression . Linear regression is arguably the simplest linear model, and comes with four assumptions: . Linearity: The relationship between $X$ and the mean of $y$ is linear. | Independence: $X_i$ and $X_j$ are linearly independent of eachother for all $i neq j$. | Normality: $y$ given any $X$ comes from a normal distribution. | Homoscedasticity: The variance of the error is the same for any value of $X$. | These assumptions can be nicely described by one math equation: . $$ begin{aligned} y &amp; in mathcal{N}(X^T beta, sigma^2 I) &amp; Rightarrow mathbb{E}[y|X] = mu(X) = X^T beta end{aligned} $$Unfortunately, these assumptions are quite rigid for the real world. Many datasets do not conform to these restrictions. So why do we still use linear regression when we have algorithms that can perform the regression task without such rigid assumptions? The common answers to this question are: . Occam&#39;s Razor: Don&#39;t add complexity without necessity. | Little Data: Ordinary Least Squares (OLS) is a closed form solution to linear regression2. | Interpretability: $y$ can be explained with respect to how $X$ interacts with the $ beta$ coefficients. | Today, we are going to stick with the notion that transparency is of the utmost importance, and assume we have a significant amount of data. Whatever the model is, it must be able to produce feature-wise explanations that are useful. However, these models don&#39;t need to be exactly linear in order to be interpretable. . Generalized Linear Models (GLMs) . Generalized Linear Model (GLM), introduced in (missing reference), loosen the constraints of normality, linearity, and homoscedasticity described in the previous section via the following specifications: . Random Component: The probability distribution of $y$ (typically belonging to the exponential family3). | Systematic Component: the right side of the equation for predicting $y$ (typically $X^T beta$). | Link Function: A function $g$ that links the systematic component and the random component. | This yields the following general equation for GLMs: . $$g( mathbb{E}[y|X]) = X^T beta + epsilon$$ . Observe that if the random component is a normal distribution with a constant variance, and the link function is the identity function ($g(y) = y$), then the corresponding GLM is exactly linear regression! Hence, the functions that GLMs can describe are a superset of the functions linear regression can describe. . Selecting a link function according to the random component is what differentiates GLMs. The intuition behind a link function is that it transforms the distribution of $y$ to the range $(- infty,+ infty)$, as that is the expected range of $X^T beta$. As an example, binary logistic regression assumes the probability distribution of $y$ is a bernoulli distribution. This means that the average of the distribution, $ mu$, is between 0 and 1. We need some function $g: [0,1] rightarrow Reals$, and the logit function is sufficient for this: . $$g( mu) = log( frac{ mu}{1 - mu})$$ . Now, we can fit a simple linear model to $g(y) = X^T beta + epsilon$. Unfortunately, introducing a non-linear transformation to this equation means that Ordinary Least Squares is no longer a reasonable estimation method. Hence, learning $ beta$ requires a different estimation method. Maximum Likelihood Estimation (MLE) estimates the parameters of a probability distribution by maximizing the likelihood that a sample of observed data belongs to that probability distribution. In fact, under the assumptions of simple linear regression, MLE is equivalent to OLS as demonstrated on page 2 of these CMU lecture notes. The specifics of MLE are not necessary for the rest of this blog post, however if you would like to learn more about it, please refer to these Stanford lecture notes. . The Building Blocks of Neural Networks . But where do neural networks come in? Aren&#39;t they incredibly non-linear and opaque, unlike GLMs? Sort of. On the macro-level, NNs and GLMs look very different, but the micro-level tells a different story. Let&#39;s zoom into the inner workings of neural networks and see how they relate to GLMs! . Neural networks are built of components called layers. Layers are built of components called nodes. At their heart, these nodes are computational-message-passing-machines. They receive a set of inputs, perform a computation, and pass the result of that computation to other nodes in the network. These are the building blocks of neural networks. . The first layer of a neural network is called the input layer, because each node passes an input feature to all nodes in the next layer. The last layer of a neural network is called the output layer, and it should represent the output you are trying to predict (this layer has one node in the classic regression case). Lastly, any layers between the input and output layers are called hidden layers. . . In the classic fully-connected feed-forwad neural network, this structure of layers is ordered and connected such that every node $n_j$ in layer $L_i$ receives the output of every node in the predecing layer $L_{i-1}$, does some computation with those outputs, and passes the corresponding output to each node in the succeeding layer $L_{i + 1}$. The image above displays a neural network with $N$ input features, a single hidden layer, and a single output prediction $ hat{y}$. . Each node in layer $L_i$ contains some set of weights ($w$) and a bias ($b$), where the dimension of the weight vector is equal to the number of nodes in layer $L_{i - 1}$. When the node receives the output of all the nodes in the preceding layer, it performs the following computation: $L_{i - 1}^Tw + b$. . This should look familiar! It is quite literally $X^T beta$: the classic computation from linear models on the ouputs of the preceding layer! . However, before this node passes $X^T beta$ to the next layer in the network, it is passed through an activation function $f$. Activation functions often introduce non-linearity to the neural network, similar to link functions in GLMs. The image below isolates a single neuron from the image above, taking input from the previous layer, and making a prediction by transforming the output of the neuron with an activation function $ hat{y} = f(X^T beta)$. . . In fact, observe that if the activation function is invertible, this computation is equivalent to $f^{-1}( hat{y}) = X^T beta$, which is exactly a GLM with link function $f^{-1}$. This demonstrates that the computation of a single node in a neural network is, conceptually, a GLM on the output of the previous layer! . Furthermore, this means that a neural network with zero hidden layers and a linear activation function on the output layer is exactly equivalent to linear regression, as the lack of hidden layers maintains independence. And, if we change the activation function to the inverse of the logit function (this is the sigmoid activation function), this neural network becomes exactly equivalent to logistic regression! The code below is a simple prototype of building linear and logistic regression with Keras, and tests it on a simulated dataset. . class LinearRegression(tf.keras.Model): def __init__(self): super().__init__() # zero hidden layers with a linear activation on one output node self.output_layer = tf.keras.layers.Dense(1, activation=&#39;linear&#39;) def call(self, input_layer, training=None): return self.output_layer(input_layer) class LogisticRegression(tf.keras.Model): def __init__(self): super().__init__() # zero hidden layers with a sigmoid activation on one output node self.output_layer = tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;) def call(self, input_layer, training=None): return self.output_layer(input_layer) . However, It isn&#39;t always as simple as the cases of linear and logistic regression. Not all activation functions are invertible (e.g. ReLU), and hence add non-linearities in ways that are not consistent with GLMs. At the same time, the principal of the link function is to transform $y$ to the proper space, and ReLU does accomplish this under the assumption that $y$ cannot be negative. . There is clearly an intimate connection between neural networks and linear models, as the computational components of neural networks are quite literally non-linear transforms on linear models just like GLMs. So, why are neural networks opaque and GLMs transparent? Let&#39;s look at the math for regression using an arbitrarily defined neural network with $k$ hidden layers. . $$ begin{aligned} L_0&amp; = big [ X_1, X_2, cdots, X_n big ] L_1 &amp; = big [ hspace{0.5em}f_1(L_0^Tw_{1,1} + b_{1,1}), hspace{0.5em}f_1(L_0^Tw_{1,2} + b_{1,2}), cdots big ] &amp; vdots L_k &amp; = big [ hspace{0.5em}f_k(L_{k - 1}^Tw_{k,1} + b_{k,1}), hspace{0.5em}f_k(L_{k - 1}^Tw_{k,2} + b_{k,2}), cdots big ] hat{y} &amp; = L_k^T beta end{aligned} $$Where $w_{i,j}$ and $b_{i,j}$ are the weights and bias of the jth node in layer $L_i$ with activation function $f_i$. . Observe that for every layer after $L_1$, the information passed to nodes in that layer from the preceding layer are dependent on every input feature from the input layer. Hence, the inputs to the node are not linearly independent. This means that the restriction of independence breaks once a single hidden layer is introduced to the network4. This dependency is what creates the opacity of neural networks, not the non-linearity. This can be seen in the next section on Generalized Additive Models, a transparent approach with highly non-linear transforms to the input features, while maintaining some notion of independence. This will shed light on how to design neural networks with control over feature dependence! . Generalized Additive Models (GAMs) . Generalized Additive Models (GAMs), introduced in (Hastie &amp; Tibshirani, 1986), take another step towards reducing the restrictions within linear models. There are two modifications that GAMs make to classic GLMs, which truly moves from rigid assumptions to flexible modeling: . Allow non-linearity: GAMs wrap each component $X_i$ with a function $h_k$, where $h_k$ is some learned function that can be non-linear, but must be smooth5. It also can be non-parametric. . | Allow dependence: Linear models make the assumption that $X_i$ and $X_j$ are linearly independent for all $i neq j$. Additive models don&#39;t have this property, however we assume that which features interact are known apriori. This means that the systematic component can be an equation that contains non-linear feature interaction like $h_k(X_i,X_j, cdots)$. . | Hence, equations for GAMs look like this: . $$g( mu(X)) = beta_0 + h_1(X_1) + h_2(X_2, X_3) + cdots + h_m(X_n) + epsilon$$ . Technically, this makes GLMs a special case of GAMs where all functions $h_i$ simply multiply their corresponding input feature(s) by a single parameter $ beta_i$. However, unlike GLMs, these functions require a more convoluted fitting mechanism. If you are interested in the history of GAMs and how they are fit, please refer to the original papers on the backfitting algorithm: (missing reference). What follows is a simplification to provide intuition on what these $h_i$ functions are. . $$h_k(x_i) = sum_{j=1}^n b_j(x_i) beta_j$$ . Where $b_j$ is a basis-spline, $ beta_j$ is a learned coefficient corresponding to $b_j$, and $n$ is a hyperparameter describing the number of basis-splines to use to fit the GAM. A linear combination of basis-splines uniquely describes any spline function sharing the same properties (e.g. knots, degrees) as the basis-splines (Prautzsch et al., 2002), which means these $h_k$ functions are spline functions. Below is an example of fitting a smooth function ($h_k(x_i) = sin(x_i)$) using a linear combination of cubic basis-splines. . As you can see, a linear combination of many cubic b-splines was sufficient to fit this smooth function. GAMs try and fit spline functions to transform each individual dependent variable, and model the independent variable as a linear combination of these spline functions. This maintains transparency because, once fit, we can inspect the learned functions to understand exactly how our model makes predictions according to individual features. . There is so much more to learn about GAMs, such as how these splines are learned, methods of interpreting them, and important regularization penalties to ensure higher degrees of smoothness. If you would like a more extensive review on GAMs, please refer to this wonderful mini-website-textbook, however that&#39;s out of the scope of this blog post. . Now you should finally have the requisite knowledge and background on transparent models that we can get into building transparent neural networks! . Transparent Neural Networks . (Hornik et al., 1989) is the original paper suggesting NNs are a type of universal approximator. The theory of this contribution was explored in multi-layer perceptrons in (Pinkus, 1999) and generally formalized by (Balázs, 2001). The theorem can be summarized by: . A neural network with a single hidden layer of infinite width can approximate any continuous function. . If neural networks can be used to approximate any continuous function, then they can be used to approximate the non-linear, non-parametric, functions ($h_k$ in the previous section) necessary for Generalized Additive Models. Furthermore, neural networks can describe a wider set of functions than GAMs because continuous functions don&#39;t have to be smooth, while smooth functions have to be continuous. . Above are images of three functions. The first function is a linear combination of the second and third function. Observe that all three functions are continuous. We would like to build a model that can fit the first function, while maintaining feature-wise interpretability such that we can see that it properly learns the second and third functions. Unfortunately, it is not reasonable to expect a GAM to achieve this because, while the functions are continuous, they are not smooth. Below is a GAM with very very low regularization and smoothness penalties in order to let it try and fit non-smooth functions. Furthermore, it is trained and tested on the same dataset. This is a strong demonstration that GAMs cannot approach these problems, because they can&#39;t even overfit to the solution. . from pygam import LinearGAM from pygam import s as spline #fit a classic GAM with no regularization or smoothing penalties to try and #let it overfit to non-smooth functions. It still fails! gam = LinearGAM( spline(0,lam=0,penalties=None) + spline(1,lam=0,penalties=None), callbacks=[] ).fit(X, y) . While these fits aren&#39;t terrible in terms of prediction error, that&#39;s not what we care about. We care about learning the proper structure for the functions that explain the relationship between individual features and our output. The above plots are a clear demonstration that GAMs can&#39;t even overfit to provide that. . Luckily, because these functions are continuous, we can use a neural network to approximate them! . Generalized Additive Neural Networks (GANNs) . The trick is to use a different neural network for each individual feature, and add them together just like how GAMs work! By replacing the non-linear, non-parametric, functions in GAMs by neural networks, we get get Generalized Additive Neural Networks (GANNs), introduced in (Potts, 1999). Unfortunately, this contribution did not take off because we didn&#39;t have the technical capacity to train large networks as we do today. Luckily, now it is quite easy to fit such a model. . . GANNs are simply a linear combination of neural networks, where each network only observes a single input feature6. Because each of these networks take a single input feature, and provide a single output feature, it becomes possible to plot a two-dimensional graph where the x-axis is the input feature and the y-axis is the output feature for each network. This graph is hence a fully transparent function describing how the neural network learned to transform the input feature as it contributes, additively, to the prediction. Hence this type of neural architecture is sufficient for creating a model as transparent as the linear models described in this blog postso far. . Below is code for creating a GANN using Keras. As you can see, this model is capable of solving the regression problem while maintaining feature-wise transparency on piecewise continous functions! . from tensorflow.keras import layers, regularizers #define a simple multi-layer perceptron class NN(tf.keras.Model): def __init__( self, name=None ): super().__init__(name=name) # relu helps learn more jagged functions if necessary. self.l1 = layers.Dense(8, activation=&#39;relu&#39;) # softplus helps smooth between the jagged areas from above # as softplus is referred to as &quot;SmoothRELU&quot; self.l2 = layers.Dense(8, activation=&#39;softplus&#39;) self.l3 = layers.Dense(8, activation=&#39;softplus&#39;) self.l4 = layers.Dense(8, activation=&#39;softplus&#39;) self.output_layer = layers.Dense(1) def call(self, x, training=None): x = self.l1(x) x = self.l2(x) x = self.l3(x) x = self.l4(x) return self.output_layer(x) #define a Generalized Additive Neural Network for n features class GANN(tf.keras.Model): def __init__( self, n_features, name=None ): super().__init__(name=name) self.n_features = n_features # initialize MLP for each input feature self.components = [NN() for i in range(n_features)] # create final layer for a linear combination of learned components self.linear_combination = tf.keras.layers.Dense(1) @tf.function def call(self, x, training=None): #split up by individual features individual_features = tf.split(x, self.n_features, axis=1) components = [] #apply the proper MLP to each individual feature for f_idx,individual_feature in enumerate(individual_features): component = self.components[f_idx](individual_feature) components.append(component) #concatenate learned components and return linear combination of them components = tf.concat(components, axis=1) return self.linear_combination(components) . model = GANN(n_features=2) model.compile( optimizer=tf.keras.optimizers.Adam(), loss=&#39;mean_squared_error&#39;, metrics=[&#39;mean_absolute_error&#39;] ) hist = model.fit( X.to_numpy(), y.to_numpy(), epochs=50, batch_size=32, ) . At first glance, these results look good, but not perfect. The right-most-plot demonstrates this model achieved a near perfect fit of the actual task, while the first two plots look like the Neural Additive Model was capable of learning the general shapes of the functions, but is off on the intercepts for all of them. This should not discount the validity of the model. The corresponding math demonstrates perfectly fitting intercepts of an additive model cannot be guaranteed. . Let $h_i(X_i) = alpha_i + f(X_i)$ where $f(X_i)$ represents all of the aspects of $h(X_i)$ that dependent on $X_i$, and $ alpha_i$ represents the intercept. . $$ begin{aligned} y &amp; = beta_0 + sum_{i=1}^n beta_i h_i(X_i) &amp; = beta_0 + sum_{i=1}^n beta_i ( alpha_i + f_i(X_i)) &amp; = beta_0 + sum_{i=1}^n beta_i alpha_i + sum_{i=1}^n beta_i f_i(X_i) end{aligned} $$The only way to tease apart these intercepts is via $ beta$. Imagine the proper fit of this equation, for every $i$, had $ beta_i = 1$ and $ alpha_i = 2$. In this case, if half of the learned $ alpha_i$s are zero, and the other half are four, that would yield the exact same result for $ sum_{i=1}^n beta_i alpha_i$ as the proper fit. Hence, by way of contradictory example, it is impossible to guarantee learning correct intercepts for the individual components of any additive model. . The plots below are what happens when we simply adjust the learned intercepts for these functions. As you can see, by simply changing the intercept, we are able to show a near perfect fit of these functions, which is the best we can ever hope to do! . This is a clear deomonstration that Generalized Additive Neural Networks are capable of overfitting to piecewise continuous functions while maintaining transparency! . However, this is still just a toy example. The next section delves into Neural Additive Models (NAMs), which are a special variant of GANNs that are designed to be able to fit &quot;jumpy functions&quot;, as this is more reminiscient of real-world data. . Neural Additive Models (NAMs) . (Agarwal et al., 2020) . Generalizing the Computational Graph . This is the fun part. This is where all your creativity can yield an extremely flexible, powerful, and interpretable model! The world is your oyster, and you can use your understanding of neural networks and additive models to design an architecture that accomplishes your goals. . References Hastie, T., &amp; Tibshirani, R. (1986). Generalized Additive Models. Statist. Sci., 1(3), 297–310. https://doi.org/10.1214/ss/1177013604 | Prautzsch, H., Boehm, W., &amp; Paluszny, M. (2002). Bézier and B-Spline Techniques. https://doi.org/10.1007/978-3-662-04919-8 | Hornik, K., Stinchcombe, M., &amp; White, H. (1989). Multilayer feedforward networks are universal approximators. Neural Networks, 2(5), 359–366. https://doi.org/https://doi.org/10.1016/0893-6080(89)90020-8 | Pinkus, A. (1999). Approximation theory of the MLP model in neural networks. Acta Numerica, 8, 143–195. https://doi.org/10.1017/S0962492900002919 | Balázs, C. (2001). Approximation with Artificial Neural Networks. https://doi.org/10.1.1.101.2647 | Potts, W. J. E. (1999). Generalized Additive Neural Networks. Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 194–200. https://doi.org/10.1145/312129.312228 | Agarwal, R., Frosst, N., Zhang, X., Caruana, R., &amp; Hinton, G. E. (2020). Neural Additive Models: Interpretable Machine Learning with Neural Nets. | . Footnotes . the nuances of fitting these models (e.g. Maximum Likelihood Estimation, Backfitting, Gradient Descent) are not covered in detail in this blog post. There are links to papers and lectures on these topics in their corresponding sections if you would like to read about them.↩ | The closed form solution for OLS is $ beta = (X^TX)^ inv X^Ty$. This requires $X^TX$ to be invertible, which is the case when the elements in $X$ are linearly independent. This is satisfied by our assumption of independence. Without this assumption, there is no closed form solution, and $ beta$ can be approximated by the maximum likelihood estimation function: $min_ beta(y - beta X)^T(y - beta X)$.↩ | The exponential family is a particular family of probability distributions such that their probability density function (PDF) can be writted as: $P(x | theta) = f(x) g( theta) exp Big( eta( theta) centerdot T(x) Big)$, where $f$, $g$, $ eta$, and $T$ are known functions and $ theta in Reals$ is the only parameter to the PDF.↩ | This explains why we could create a model identical to linear and logistic regression by designing a neural network with zero hidden layers.↩ | The &quot;smoothness&quot; of a function is described by the continuity of the derivatives. The set of functions with a smoothness of 0 is equivalent to the set of continuous functions. The set of functions with a smoothness of 1 is the set of continuous functions such that their first derivative is continuous. So on, and so forth. Generally, a function is considered &quot;smooth&quot; if it has &quot;smoothness&quot; of $ infty$. In other words, it is infinitely differentiable.↩ | Technically, this could be fit where the sub-networks take more than a single feature as input, but this comes at a cost of interpretability. It is still possible to explore the relationship between both features and the output, however it becomes high-dimensional, entangled, and hence more difficult to interpret.↩ |",
            "url": "https://ryansaxe.com/transparency/2020/12/01/NAM.html",
            "relUrl": "/transparency/2020/12/01/NAM.html",
            "date": " • Dec 1, 2020"
        }
        
    
  

  
  

  

  

  

  

  
  

  

  
  

  

  

  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ryansaxe.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}