<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://ryansaxe.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ryansaxe.com/" rel="alternate" type="text/html" /><updated>2020-12-30T15:52:07-06:00</updated><id>https://ryansaxe.com/feed.xml</id><title type="html">Opening the Black Box</title><subtitle>explaining and exploring how machines learn</subtitle><entry><title type="html">Designing Interpretable Neural Networks</title><link href="https://ryansaxe.com/transparency/2020/12/01/NAM.html" rel="alternate" type="text/html" title="Designing Interpretable Neural Networks" /><published>2020-12-01T00:00:00-06:00</published><updated>2020-12-01T00:00:00-06:00</updated><id>https://ryansaxe.com/transparency/2020/12/01/NAM</id><author><name></name></author><category term="transparency" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ryansaxe.com/images/nnflow.png" /><media:content medium="image" url="https://ryansaxe.com/images/nnflow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>