<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://ryansaxe.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ryansaxe.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-12-01T17:43:18-06:00</updated><id>https://ryansaxe.github.io/blog/feed.xml</id><title type="html">Opening the Black Box</title><subtitle>A blog dedicated to exploring &amp; explaining how machines learn.</subtitle><entry><title type="html">Neural Networks as Interpretable as Linear Models</title><link href="https://ryansaxe.github.io/blog/jupyter/2020/12/01/NAM.html" rel="alternate" type="text/html" title="Neural Networks as Interpretable as Linear Models" /><published>2020-12-01T00:00:00-06:00</published><updated>2020-12-01T00:00:00-06:00</updated><id>https://ryansaxe.github.io/blog/jupyter/2020/12/01/NAM</id><author><name></name></author><category term="jupyter" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ryansaxe.github.io/blog/images/nnflow.png" /><media:content medium="image" url="https://ryansaxe.github.io/blog/images/nnflow.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>